---
layout: post
date: 2025-10-04 15:59:00-0400
inline: true
related_posts: false
---

Preprint alert: [Not all Data are Unlearned Equally](https://arxiv.org/abs/2504.05058). We show that pretraining exposure influences the success of LLM unlearning.
